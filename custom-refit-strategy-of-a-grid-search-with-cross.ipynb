{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Custom refit strategy of a grid search with cross-validation\nThis examples shows how a classifier is optimized by cross-validation, which is done using the GridSearchCV object on a development set that comprises only half of the available labeled data.\n\nThe performance of the selected hyper-parameters and trained model is then measured on a dedicated evaluation set that was not used during the model selection step.","metadata":{}},{"cell_type":"markdown","source":"# The dataset\nWe will work with the digits dataset. The goal is to classify handwritten digits images. We transform the problem into a binary classification for easier understanding: the goal is to identify whether a digit is 8 or not.","metadata":{}},{"cell_type":"code","source":"from sklearn import datasets\n\ndigits = datasets.load_digits()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T18:52:26.375905Z","iopub.execute_input":"2025-05-08T18:52:26.376442Z","iopub.status.idle":"2025-05-08T18:52:26.397837Z","shell.execute_reply.started":"2025-05-08T18:52:26.376376Z","shell.execute_reply":"2025-05-08T18:52:26.396790Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"n_samples = len(digits.images)\nX = digits.images.reshape((n_samples, -1))\ny = digits.target == 8\nprint(\n    f\"The number of images is {X.shape[0]} and each image contains {X.shape[1]} pixels\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:40:34.554522Z","iopub.execute_input":"2025-05-08T19:40:34.555810Z","iopub.status.idle":"2025-05-08T19:40:34.566348Z","shell.execute_reply.started":"2025-05-08T19:40:34.555771Z","shell.execute_reply":"2025-05-08T19:40:34.564940Z"}},"outputs":[{"name":"stdout","text":"The number of images is 1797 and each image contains 64 pixels\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:40:51.945165Z","iopub.execute_input":"2025-05-08T19:40:51.946395Z","iopub.status.idle":"2025-05-08T19:40:52.093045Z","shell.execute_reply.started":"2025-05-08T19:40:51.946362Z","shell.execute_reply":"2025-05-08T19:40:52.091833Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Define our grid-search strategy\nWe will select a classifier by searching the best hyper-parameters on folds of the training set. To do this, we need to define the scores to select the best candidate.","metadata":{}},{"cell_type":"code","source":"scores = [\"precision\", \"recall\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:42:55.587676Z","iopub.execute_input":"2025-05-08T19:42:55.588135Z","iopub.status.idle":"2025-05-08T19:42:55.594139Z","shell.execute_reply.started":"2025-05-08T19:42:55.588106Z","shell.execute_reply":"2025-05-08T19:42:55.592545Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"We can also define a function to be passed to the refit parameter of the GridSearchCV instance. It will implement the custom strategy to select the best candidate from the cv_results_ attribute of the GridSearchCV. Once the candidate is selected, it is automatically refitted by the GridSearchCV instance.\n\nHere, the strategy is to short-list the models which are the best in terms of precision and recall. From the selected models, we finally select the fastest model at predicting. Notice that these custom choices are completely arbitrary.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n\ndef print_dataframe(filtered_cv_results):\n    \"\"\"Pretty print for filtered dataframe\"\"\"\n    for mean_precision, std_precision, mean_recall, std_recall, params in zip(\n        filtered_cv_results[\"mean_test_precision\"],\n        filtered_cv_results[\"std_test_precision\"],\n        filtered_cv_results[\"mean_test_recall\"],\n        filtered_cv_results[\"std_test_recall\"],\n        filtered_cv_results[\"params\"],\n    ):\n        print(\n            f\"precision: {mean_precision:0.3f} (±{std_precision:0.03f}),\"\n            f\" recall: {mean_recall:0.3f} (±{std_recall:0.03f}),\"\n            f\" for {params}\"\n        )\n    print()\n\n\ndef refit_strategy(cv_results):\n    \"\"\"Define the strategy to select the best estimator.\n\n    The strategy defined here is to filter-out all results below a precision threshold\n    of 0.98, rank the remaining by recall and keep all models with one standard\n    deviation of the best by recall. Once these models are selected, we can select the\n    fastest model to predict.\n\n    Parameters\n    ----------\n    cv_results : dict of numpy (masked) ndarrays\n        CV results as returned by the `GridSearchCV`.\n\n    Returns\n    -------\n    best_index : int\n        The index of the best estimator as it appears in `cv_results`.\n    \"\"\"\n    # print the info about the grid-search for the different scores\n    precision_threshold = 0.98\n\n    cv_results_ = pd.DataFrame(cv_results)\n    print(\"All grid-search results:\")\n    print_dataframe(cv_results_)\n\n    # Filter-out all results below the threshold\n    high_precision_cv_results = cv_results_[\n        cv_results_[\"mean_test_precision\"] > precision_threshold\n    ]\n\n    print(f\"Models with a precision higher than {precision_threshold}:\")\n    print_dataframe(high_precision_cv_results)\n\n    high_precision_cv_results = high_precision_cv_results[\n        [\n            \"mean_score_time\",\n            \"mean_test_recall\",\n            \"std_test_recall\",\n            \"mean_test_precision\",\n            \"std_test_precision\",\n            \"rank_test_recall\",\n            \"rank_test_precision\",\n            \"params\",\n        ]\n    ]\n\n    # Select the most performant models in terms of recall\n    # (within 1 sigma from the best)\n    best_recall_std = high_precision_cv_results[\"mean_test_recall\"].std()\n    best_recall = high_precision_cv_results[\"mean_test_recall\"].max()\n    best_recall_threshold = best_recall - best_recall_std\n\n    high_recall_cv_results = high_precision_cv_results[\n        high_precision_cv_results[\"mean_test_recall\"] > best_recall_threshold\n    ]\n    print(\n        \"Out of the previously selected high precision models, we keep all the\\n\"\n        \"the models within one standard deviation of the highest recall model:\"\n    )\n    print_dataframe(high_recall_cv_results)\n\n    # From the best candidates, select the fastest model to predict\n    fastest_top_recall_high_precision_index = high_recall_cv_results[\n        \"mean_score_time\"\n    ].idxmin()\n\n    print(\n        \"\\nThe selected final model is the fastest to predict out of the previously\\n\"\n        \"selected subset of best models based on precision and recall.\\n\"\n        \"Its scoring time is:\\n\\n\"\n        f\"{high_recall_cv_results.loc[fastest_top_recall_high_precision_index]}\"\n    )\n\n    return fastest_top_recall_high_precision_index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:42:58.259450Z","iopub.execute_input":"2025-05-08T19:42:58.259864Z","iopub.status.idle":"2025-05-08T19:42:58.271623Z","shell.execute_reply.started":"2025-05-08T19:42:58.259835Z","shell.execute_reply":"2025-05-08T19:42:58.270408Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Tuning hyper-parameters\nOnce we defined our strategy to select the best model, we define the values of the hyper-parameters and create the grid-search instance:","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\n\ntuned_parameters = [\n    {\"kernel\": [\"rbf\"], \"gamma\": [1e-3, 1e-4], \"C\": [1, 10, 100, 1000]},\n    {\"kernel\": [\"linear\"], \"C\": [1, 10, 100, 1000]},\n]\n\ngrid_search = GridSearchCV(\n    SVC(), tuned_parameters, scoring=scores, refit=refit_strategy\n)\ngrid_search.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:43:02.713059Z","iopub.execute_input":"2025-05-08T19:43:02.713406Z","iopub.status.idle":"2025-05-08T19:43:14.771754Z","shell.execute_reply.started":"2025-05-08T19:43:02.713385Z","shell.execute_reply":"2025-05-08T19:43:14.770829Z"}},"outputs":[{"name":"stdout","text":"All grid-search results:\nprecision: 1.000 (±0.000), recall: 0.854 (±0.063), for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\nprecision: 1.000 (±0.000), recall: 0.257 (±0.061), for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\nprecision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\nprecision: 0.968 (±0.039), recall: 0.780 (±0.083), for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\nprecision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\nprecision: 0.905 (±0.058), recall: 0.889 (±0.074), for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\nprecision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\nprecision: 0.904 (±0.058), recall: 0.890 (±0.073), for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\nprecision: 0.695 (±0.073), recall: 0.743 (±0.065), for {'C': 1, 'kernel': 'linear'}\nprecision: 0.643 (±0.066), recall: 0.757 (±0.066), for {'C': 10, 'kernel': 'linear'}\nprecision: 0.611 (±0.028), recall: 0.744 (±0.044), for {'C': 100, 'kernel': 'linear'}\nprecision: 0.618 (±0.039), recall: 0.744 (±0.044), for {'C': 1000, 'kernel': 'linear'}\n\nModels with a precision higher than 0.98:\nprecision: 1.000 (±0.000), recall: 0.854 (±0.063), for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\nprecision: 1.000 (±0.000), recall: 0.257 (±0.061), for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\nprecision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\nprecision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\nprecision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n\nOut of the previously selected high precision models, we keep all the\nthe models within one standard deviation of the highest recall model:\nprecision: 1.000 (±0.000), recall: 0.854 (±0.063), for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\nprecision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\nprecision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\nprecision: 1.000 (±0.000), recall: 0.877 (±0.069), for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n\n\nThe selected final model is the fastest to predict out of the previously\nselected subset of best models based on precision and recall.\nIts scoring time is:\n\nmean_score_time                                           0.004711\nmean_test_recall                                          0.877206\nstd_test_recall                                           0.069196\nmean_test_precision                                            1.0\nstd_test_precision                                             0.0\nrank_test_recall                                                 3\nrank_test_precision                                              1\nparams                 {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\nName: 4, dtype: object\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"GridSearchCV(estimator=SVC(),\n             param_grid=[{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n                          'kernel': ['rbf']},\n                         {'C': [1, 10, 100, 1000], 'kernel': ['linear']}],\n             refit=<function refit_strategy at 0x7875cf759940>,\n             scoring=['precision', 'recall'])","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n             param_grid=[{&#x27;C&#x27;: [1, 10, 100, 1000], &#x27;gamma&#x27;: [0.001, 0.0001],\n                          &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n                         {&#x27;C&#x27;: [1, 10, 100, 1000], &#x27;kernel&#x27;: [&#x27;linear&#x27;]}],\n             refit=&lt;function refit_strategy at 0x7875cf759940&gt;,\n             scoring=[&#x27;precision&#x27;, &#x27;recall&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n             param_grid=[{&#x27;C&#x27;: [1, 10, 100, 1000], &#x27;gamma&#x27;: [0.001, 0.0001],\n                          &#x27;kernel&#x27;: [&#x27;rbf&#x27;]},\n                         {&#x27;C&#x27;: [1, 10, 100, 1000], &#x27;kernel&#x27;: [&#x27;linear&#x27;]}],\n             refit=&lt;function refit_strategy at 0x7875cf759940&gt;,\n             scoring=[&#x27;precision&#x27;, &#x27;recall&#x27;])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"grid_search.best_params_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:43:27.809893Z","iopub.execute_input":"2025-05-08T19:43:27.810229Z","iopub.status.idle":"2025-05-08T19:43:27.816311Z","shell.execute_reply.started":"2025-05-08T19:43:27.810208Z","shell.execute_reply":"2025-05-08T19:43:27.815458Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"Finally, we evaluate the fine-tuned model on the left-out evaluation set: the grid_search object has automatically been refit on the full training set with the parameters selected by our custom refit strategy.\n\nWe can use the classification report to compute standard classification metrics on the left-out set:","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ny_pred = grid_search.predict(X_test)\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:43:55.803102Z","iopub.execute_input":"2025-05-08T19:43:55.803415Z","iopub.status.idle":"2025-05-08T19:43:55.827927Z","shell.execute_reply.started":"2025-05-08T19:43:55.803393Z","shell.execute_reply":"2025-05-08T19:43:55.826978Z"}},"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n       False       0.99      1.00      0.99       807\n        True       1.00      0.87      0.93        92\n\n    accuracy                           0.99       899\n   macro avg       0.99      0.93      0.96       899\nweighted avg       0.99      0.99      0.99       899\n\n","output_type":"stream"}],"execution_count":12}]}